---
title: "Statistical Rethinking Notes - Chapter 3"
author: Zachary Levonian
date: 2022
output: pdf_document
---

# Chapter 3

```{r, message=FALSE}
library(rethinking)
library(scales)  # for alpha in the plots
```

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prob_p <- rep( 1 , 1000 )
prob_data <- dbinom(4, size=6, prob=p_grid)
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)
```

```{r}
plot(p_grid, posterior, type="l")
```



```{r, figures-side, fig.show="hold", out.width="50%"}
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
plot(samples)
dens(samples)
lines(p_grid, posterior * 1000, lty=2)  # why do I need to multiply by 1000?
```

```{r}
#dbinom(4, size=6, prob=0.5)  # binomial density at 0.5; probability of getting 4 or less lands from 6 tosses, given Pr(L) = 0.5
sum(posterior[p_grid < 0.5])  # grid approximation
sum(samples < 0.5 ) / 1e4  # samples approximation
```


```{r}
xs <- seq( from=0 , to=1 , length.out=1000 )
plot(xs, pbinom(4, 6, xs), type="l")
```

```{r}
quantile(samples, c(0.1 , 0.9))
# PI = "percentile interval"
PI(samples , prob=0.8)  # convenience form of the above
# HPDI = "highest posterior density interval"
HPDI(samples , prob=0.8)
```

```{r}
plot(p_grid, posterior, type="l")
x <- p_grid

# in green, the highest posterior density interval
bounds <- HPDI(samples, prob=0.8)
lb <- bounds[1]
ub <- bounds[2]
polygon(c(x[x>=lb & x<ub], ub, lb), c(posterior[x>=lb & x<ub], 0, 0), col=alpha("#008999", 0.4))

# in pink, the percentile interval
bounds <- PI(samples, prob=0.8)
lb <- bounds[1]
ub <- bounds[2]
polygon(c(x[x>=lb & x<ub], ub, lb), c(posterior[x>=lb & x<ub], 0, 0), col=alpha("#FF3399", 0.4))
```

```{r}
# MAP point estimation (Maximum a posteriori)
p_grid[which.max(posterior)]
chainmode(samples , adj=0.01)  # samples based approximation
```
